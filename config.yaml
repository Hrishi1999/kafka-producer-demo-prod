# SQL to Kafka Producer Configuration

database:
  host: ${SQL_SERVER_HOST}
  port: 1433
  database: ${SQL_DATABASE}
  username: ${SQL_USERNAME}
  password: ${SQL_PASSWORD}

kafka:
  bootstrap_servers: ${KAFKA_BOOTSTRAP_SERVERS}
  security_protocol: SASL_SSL
  sasl_mechanism: PLAIN
  sasl_username: ${KAFKA_USERNAME}
  sasl_password: ${KAFKA_PASSWORD}
  schema_registry_url: ${SCHEMA_REGISTRY_URL}
  schema_registry_username: ${SCHEMA_REGISTRY_USERNAME}
  schema_registry_password: ${SCHEMA_REGISTRY_PASSWORD}
  
  # Transactional settings for exactly-once semantics
  enable_transactions: ${ENABLE_KAFKA_TRANSACTIONS:false}
  transactional_id: ${KAFKA_TRANSACTIONAL_ID:sql-producer-001-${ENVIRONMENT:dev}-v1}
  transaction_timeout_ms: 60000
  
  # DLQ and retry configuration
  dlq:
    enabled: ${KAFKA_DLQ_ENABLED:true}
    topic_suffix: ".dlq"
    retry_topic_suffix: ".retry"
    max_retries: 3
    retry_delay_seconds: [30, 300, 1800]  # 30s, 5m, 30m
    circuit_breaker_failure_threshold: 5
    circuit_breaker_timeout_seconds: 300

queries:
  - id: customer_updates
    name: Customer Updates
    sql: |
      SELECT 
        customer_id,
        name,
        email,
        updated_at,
        GETDATE() as extracted_at
      FROM customers
      WHERE updated_at > DATEADD(hour, -1, GETDATE())
      ORDER BY updated_at
    target_topic: sql.customers.updates
    key_column: customer_id
    batch_size: 1000
    schedule: "*/5 * * * *"  # Every 5 minutes (cron style)
    enabled: true

  - id: order_events
    name: Recent Orders
    sql: |
      SELECT 
        order_id,
        customer_id,
        order_status,
        order_total,
        created_at
      FROM orders
      WHERE created_at > DATEADD(second, -10, GETDATE())  -- Only last 10 seconds of data
      ORDER BY created_at DESC
    target_topic: sql.orders.events
    key_column: order_id
    batch_size: 100  # Smaller batches for 5-second intervals
    fetch_size: 100
    schedule: "interval:5s"  # Every 5 seconds
    timeout_seconds: 4  # Less than 5s to avoid overlap
    enabled: true

monitoring:
  enabled: true
  metrics_port: 8080
  log_level: "INFO"
  log_format: "json"
  log_file: "logs/sql-kafka-producer.log"
  max_log_file_size_mb: 10
  log_backup_count: 5

# Global settings optimized for 5-second intervals
state_file: "state.json"
checkpoint_interval_seconds: 10  # Checkpoint every 10 seconds for 5s intervals
worker_threads: 4